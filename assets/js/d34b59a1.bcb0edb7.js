"use strict";(self.webpackChunkmy_docs_website=self.webpackChunkmy_docs_website||[]).push([[8470],{30534:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>l});var s=t(74848),n=t(28453);const i={slug:"vector-search",title:"Vector capabilities of OceanBase Database: find similar images in a blink"},o=void 0,r={id:"blogs/tech/vector-search",title:"Vector capabilities of OceanBase Database: find similar images in a blink",description:"Basic capabilities of a vector database",source:"@site/docs/blogs/tech/vector-search.md",sourceDirName:"blogs/tech",slug:"/blogs/tech/vector-search",permalink:"/docs/blogs/tech/vector-search",draft:!1,unlisted:!1,editUrl:"https://github.com/oceanbase/oceanbase.github.io/tree/main/docs/blogs/tech/vector-search.md",tags:[],version:"current",frontMatter:{slug:"vector-search",title:"Vector capabilities of OceanBase Database: find similar images in a blink"},sidebar:"blogsSidebar",previous:{title:"Principles and Practices of Transaction Recovery in Distributed Databases",permalink:"/docs/blogs/tech/trans-recovery"},next:{title:"How Did AXA SPDB Select a Database Service to Meet Both OLTP and OLAP Requirements?",permalink:"/docs/blogs/users/AXA"}},c={},l=[{value:"Basic capabilities of a vector database",id:"basic-capabilities-of-a-vector-database",level:2},{value:"Vector storage capability of OceanBase Database",id:"vector-storage-capability-of-oceanbase-database",level:2},{value:"1. Deploy an OceanBase vector database in Docker",id:"1-deploy-an-oceanbase-vector-database-in-docker",level:3},{value:"2. Process image data",id:"2-process-image-data",level:3},{value:"3. Connect to OceanBase Database by using a Python library",id:"3-connect-to-oceanbase-database-by-using-a-python-library",level:3},{value:"4. Define a vector processing interface",id:"4-define-a-vector-processing-interface",level:3},{value:"5. Import images into OceanBase Database",id:"5-import-images-into-oceanbase-database",level:3},{value:"6. Perform reverse image search",id:"6-perform-reverse-image-search",level:3},{value:"7. Create a vector index",id:"7-create-a-vector-index",level:3},{value:"Use AI technologies to empower vector capabilities",id:"use-ai-technologies-to-empower-vector-capabilities",level:2}];function d(e){const a={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,n.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(a.h2,{id:"basic-capabilities-of-a-vector-database",children:"Basic capabilities of a vector database"}),"\n",(0,s.jsx)(a.p,{children:"Generally, AI technologies are applied in a database storage system for the following two purposes:"}),"\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.strong,{children:"First, approximate search."})," In this application architecture, unstructured data is transformed into vectors and stored in a database with the help of Large Language Model (LLM) embeddings. This way, the database can perform vector operations and similarity search, and supports search recommendations and queries of unstructured data."]}),"\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.strong,{children:"Second, retrieval-augmented generation (RAG)."})," It's true that LLMs provide general capabilities such as natural language conversation, text summarization, agents, and coding assistants. However, they are trained using limited knowledge and often perform awkwardly in dealing with the humongous amount of fresh knowledge generated online. A common solution, for example, is to build a database to host a Q&A corpus and provide a corpus-based information retrieval service for LLMs. This process is called RAG."]}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"1715577106",src:t(20527).A+"",width:"870",height:"736"})}),"\n",(0,s.jsxs)(a.p,{children:["OceanBase Database Community Edition supports the following basic capabilities of a vector database. For more information, see the ",(0,s.jsx)(a.a,{href:"https://github.com/oceanbase/oceanbase/tree/vector_search",children:"vector_search"})," branch on GitHub."]}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"Definition and storage of the VECTOR data type."}),"\n",(0,s.jsx)(a.li,{children:"Creation of an approximate nearest neighbor (ANN) index on a vector column. Supported indexing algorithms include Inverted File with Flat Compression (IVFFlat) and Hierarchical Navigable Small World (HNSW)."}),"\n",(0,s.jsx)(a.li,{children:"Parallel creation of ANN indexes on partitions."}),"\n",(0,s.jsx)(a.li,{children:"Parallel execution of ANN search on partitions."}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"These capabilities enable OceanBase Database to support the aforesaid two AI application architectures as the underlying storage system. In the following example, a reverse image search application is used to demonstrate the vector storage capability of OceanBase Database based on the approximate search architecture."}),"\n",(0,s.jsx)(a.h2,{id:"vector-storage-capability-of-oceanbase-database",children:"Vector storage capability of OceanBase Database"}),"\n",(0,s.jsx)(a.h3,{id:"1-deploy-an-oceanbase-vector-database-in-docker",children:"1. Deploy an OceanBase vector database in Docker"}),"\n",(0,s.jsx)(a.p,{children:"Run the following command to install the vector database:"}),"\n",(0,s.jsxs)(a.p,{children:["docker run -p 2881:2881 --name obvec -d oceanbase/oceanbase-ce",":vector"]}),"\n",(0,s.jsxs)(a.p,{children:["The database is ready to work when the docker container returns the ",(0,s.jsx)(a.code,{children:"boot success!"})," message. You can test the vector processing capability of OceanBase Database using its SQL APIs based on the following example. Run the following command to open a shell on the docker container:"]}),"\n",(0,s.jsx)(a.p,{children:"docker exec -it obvec bash"}),"\n",(0,s.jsx)(a.p,{children:"Connect to OceanBase Database:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"10",src:t(13396).A+"",width:"2560",height:"2240"})}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:["A vector data table named ",(0,s.jsx)(a.code,{children:"t1"})," is created. It contains a vector column ",(0,s.jsx)(a.code,{children:"c1"}),"."]}),"\n",(0,s.jsx)(a.li,{children:"Vector data is into the table. Note how vector data is defined by constant values in OceanBase Database."}),"\n",(0,s.jsxs)(a.li,{children:["An ",(0,s.jsx)(a.code,{children:"HNSW"})," vector index is created on this vector data table. An ",(0,s.jsx)(a.code,{children:"IVFFlat"})," index is also supported."]}),"\n",(0,s.jsx)(a.li,{children:"A full table scan is performed on the vector data table."}),"\n",(0,s.jsxs)(a.li,{children:["Typical ANN search is performed by the following statement: ",(0,s.jsx)(a.code,{children:"select XXX from XX order by XXX limit XX"}),"."]}),"\n",(0,s.jsx)(a.li,{children:"<->: specifies to calculate the Euclidean distance between two vectors."}),"\n",(0,s.jsx)(a.li,{children:"<@>: specifies to calculate the inner product between two vectors."}),"\n",(0,s.jsx)(a.li,{children:"<~>: specifies to calculate the cosine distance between two vectors."}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"2-process-image-data",children:"2. Process image data"}),"\n",(0,s.jsx)(a.p,{children:"You can use any categorized image library as the dataset. In this example, an image library is downloaded from the following link:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://www.cvmart.net/dataSets/detail/529?channel_id=op10&utm_source=cvmartmp&utm_campaign=datasets&utm_medium=article",children:"https://www.cvmart.net/dataSets/detail/529?channel_id=op10&utm_source=cvmartmp&utm_campaign=datasets&utm_medium=article"})}),"\n",(0,s.jsx)(a.p,{children:"This library contains images of different sizes, which makes it unsuitable for conventional machine learning applications that require uniform image sizes. This is not a problem here, as an embedding model is used for vector search. However, it is necessary to move all the images from their respective categorized directories to a single directory:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"2",src:t(55869).A+"",width:"2560",height:"968"})}),"\n",(0,s.jsx)(a.h3,{id:"3-connect-to-oceanbase-database-by-using-a-python-library",children:"3. Connect to OceanBase Database by using a Python library"}),"\n",(0,s.jsxs)(a.p,{children:["The following example connects to OceanBase Database by using the ",(0,s.jsx)(a.code,{children:"sqlalchemy"})," library. The VECTOR type is not supported in the MySQL dialect, so a custom Vector class is defined to implement a method that converts the VECTOR type to a Python list type, and then to constants supported by the OceanBase vector database:"]}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"3",src:t(34740).A+"",width:"2560",height:"2606"})}),"\n",(0,s.jsxs)(a.p,{children:["When the docker image of OceanBase Database starts, it automatically creates a ",(0,s.jsx)(a.code,{children:"test"})," tenant and enables port 2881 for MySQL services. You can construct a connection string to create a connection."]}),"\n",(0,s.jsx)(a.h3,{id:"4-define-a-vector-processing-interface",children:"4. Define a vector processing interface"}),"\n",(0,s.jsx)(a.p,{children:"Define a Python interface for processing vectors in OceanBase Database:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"1",src:t(74662).A+"",width:"2560",height:"3016"})}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.code,{children:"ob_create_img2img"}),": Creates a vector data table. You need to pass in the vector dimension. OceanBase Database allows you to insert only vectors with the fixed dimension to a vector data table. For the reverse image search application, the table schema is defined as follows:"]}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.code,{children:"id"}),": the unique id number that is assigned to an image, and is used as the primary key of the vector data."]}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.code,{children:"embedding"}),": stores the vector data embedded in an image for ANN search."]}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.code,{children:"path"}),": the path of an image. After similar vectors are found based on the ",(0,s.jsx)(a.code,{children:"embedding"})," field, the ",(0,s.jsx)(a.code,{children:"path"})," field is used to display the images."]}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.code,{children:"ob_insert_img2img"}),": inserts vector data into the vector data table."]}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.code,{children:"ob_ann_search"}),": executes ANN search and calculates the time consumed in the search."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"5-import-images-into-oceanbase-database",children:"5. Import images into OceanBase Database"}),"\n",(0,s.jsx)(a.p,{children:"We use the Contrastive Language-Image Pretraining (CLIP) model to convert images to vectors. You can download the CLIP model from Towhee as follows:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"4",src:t(84651).A+"",width:"2560",height:"558"})}),"\n",(0,s.jsx)(a.p,{children:"You can run the following command to obtain vectors:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"5",src:t(94146).A+"",width:"2560",height:"446"})}),"\n",(0,s.jsx)(a.p,{children:"Then, you can use the following commands to combine the whole pipeline, convert all images in the image library to vectors, and then insert the vectors into OceanBase Database. Note that you need to run the vector data table creation command for the first insertion:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"6",src:t(77081).A+"",width:"2560",height:"1192"})}),"\n",(0,s.jsx)(a.p,{children:"Create a MySQL connection and query the number of vectors. In this example, 5,399 vectors with 512 dimensions are imported:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"7",src:t(70832).A+"",width:"2560",height:"1116"})}),"\n",(0,s.jsx)(a.h3,{id:"6-perform-reverse-image-search",children:"6. Perform reverse image search"}),"\n",(0,s.jsx)(a.p,{children:"We use Gradio to create a simple web UI that provides the following two inputs:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.code,{children:"Image upload component"}),": uploads the image to be queried."]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.code,{children:"topK slider"}),": sets the top K values for ANN search."]}),"\n"]}),"\n",(0,s.jsxs)(a.p,{children:["During the search, the uploaded image is written to a temporary directory and converted to a vector. Then, the pre-defined ",(0,s.jsx)(a.code,{children:"ob_ann_search"})," function is called to obtain paths of the nearest images. At last, similar images are displayed by the gallery component:"]}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"8",src:t(87191).A+"",width:"2560",height:"1452"})}),"\n",(0,s.jsx)(a.p,{children:"Upload an image for a test. The results are as follows:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{src:"https://obcommunityprod.oss-cn-shanghai.aliyuncs.com/prod/blog/2024-05/1715577126624.png",alt:"1715577126"})}),"\n",(0,s.jsx)(a.p,{children:"Images in the results are all about seals."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{src:"https://obcommunityprod.oss-cn-shanghai.aliyuncs.com/prod/blog/2024-05/1715577132902.png",alt:"1715577132"})}),"\n",(0,s.jsx)(a.h3,{id:"7-create-a-vector-index",children:"7. Create a vector index"}),"\n",(0,s.jsx)(a.p,{children:"Create a MySQL connection and then create an IVFFlat index:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"9",src:t(87694).A+"",width:"2560",height:"446"})}),"\n",(0,s.jsx)(a.p,{children:"Optimized by the vector index, the time required to obtain the top 9 results is shortened from 39 ms to 7.6 ms:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{src:"https://obcommunityprod.oss-cn-shanghai.aliyuncs.com/prod/blog/2024-05/1715577147216.png",alt:"1715577147"})}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{src:"https://obcommunityprod.oss-cn-shanghai.aliyuncs.com/prod/blog/2024-05/1715577153205.png",alt:"1715577153"})}),"\n",(0,s.jsx)(a.h2,{id:"use-ai-technologies-to-empower-vector-capabilities",children:"Use AI technologies to empower vector capabilities"}),"\n",(0,s.jsx)(a.p,{children:"OceanBase Database adopts a native distributed architecture and stores data with a high compression ratio. Leveraging AI technologies, OceanBase Database will gain stronger storage and retrieval capabilities:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"The distributed storage engine of OceanBase Database will be able to store massive amounts of vector data."}),"\n",(0,s.jsx)(a.li,{children:"Parallel query execution on partitions can be enhanced to provide efficient vector-based approximate retrieval."}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"In other words, OceanBase users will enjoy lower storage costs, faster query speed, and more accurate query results."}),"\n",(0,s.jsx)(a.p,{children:"Moreover, compared to storing unstructured data directly, converting unstructured data into vector data through embeddings and storing vector data brings two benefits to AI applications: First, unstructured data is not directly presented to database administrators, which means higher data security. Second, it is easier for a database system to understand semantics. Vector-based approximate retrieval works on semantics. Vector values of similar text, image, and video information are close, which means that users can get accurate results with similar keywords, saving search costs and improving search efficiency."}),"\n",(0,s.jsx)(a.p,{children:"OceanBase Database now supports the approximate search and RAG application architectures."}),"\n",(0,s.jsx)(a.p,{children:"Approximate search is applicable to many scenarios, such as:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"Search recommendations"}),"\n",(0,s.jsx)(a.li,{children:"Data classification and deduplication"}),"\n",(0,s.jsx)(a.li,{children:"Vector input for generative models, such as a style transfer model"}),"\n",(0,s.jsx)(a.li,{children:"..."}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"RAG is also applicable to a range of scenarios, for example:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"Q&A based on a private knowledge base"}),"\n",(0,s.jsx)(a.li,{children:"Text2SQL"}),"\n",(0,s.jsx)(a.li,{children:"..."}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"We will continue to optimize the vector capabilities of OceanBase Database, including but not limited to simplifying the SQL syntax of ANN search, supporting GPU acceleration and more vector operation functions and vector retrieval algorithms, improving hybrid scalar/vector query performance, and providing more AI interfaces to support, for example, Matrix, which allows you to perform image transformation operations using SQL interfaces."})]})}function h(e={}){const{wrapper:a}={...(0,n.R)(),...e.components};return a?(0,s.jsx)(a,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},74662:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/1-20938cebb83987fa007fe0a59c5ae1bc.png"},13396:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/10-163614c1be3f1955c4bc19d99394de86.png"},20527:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/1715577106-e75163527ae16267a39dadb3e8c8d131.png"},55869:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/2-0bab3893fd087bce32f569ce4a906a49.png"},34740:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/3-2a63920bb50d00a88685cb87a4728c18.png"},84651:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/4-c9fbf856fa1a977cb2e4fbd1dbfbcab1.png"},94146:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/5-cf6643a8ee9b1d4f46e416ae804a5276.png"},77081:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/6-2f44e7eb842ecfa007fe7118455044e1.png"},70832:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/7-880a618af3efc71fce60a2929dc094a0.png"},87191:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/8-d1c1ae647846238a2bb5ddcd139915d9.png"},87694:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/9-329497babc463ef63f5e798eca834ac1.png"},28453:(e,a,t)=>{t.d(a,{R:()=>o,x:()=>r});var s=t(96540);const n={},i=s.createContext(n);function o(e){const a=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function r(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:o(e.components),s.createElement(i.Provider,{value:a},e.children)}}}]);