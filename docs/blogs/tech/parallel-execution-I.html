<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-blogs/tech/parallel-execution-I" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">Mastering Parallel Execution in OceanBase Database: Part 1 - Introduction | OceanBase</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://oceanbase.github.io/docs/blogs/tech/parallel-execution-I"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Mastering Parallel Execution in OceanBase Database: Part 1 - Introduction | OceanBase"><meta data-rh="true" name="description" content="Message from the Author:"><meta data-rh="true" property="og:description" content="Message from the Author:"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://oceanbase.github.io/docs/blogs/tech/parallel-execution-I"><link data-rh="true" rel="alternate" href="https://oceanbase.github.io/docs/blogs/tech/parallel-execution-I" hreflang="en"><link data-rh="true" rel="alternate" href="https://oceanbase.github.io/docs/blogs/tech/parallel-execution-I" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://6JQM9QDU5V-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.7e3a93fe.css">
<script src="/assets/js/runtime~main.6adb4f57.js" defer="defer"></script>
<script src="/assets/js/main.5def480d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="OceanBase Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.png" alt="OceanBase Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">OceanBase</b></a><a class="navbar__item navbar__link" href="/docs/blogs/arch/all-in-one">Blogs</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Docs</a><ul class="dropdown__menu"><a class="sub-dropdown dropdown__link dropdown--hoverable" style="cursor:pointer">Product Docs</a><a class="sub-dropdown dropdown__link dropdown--hoverable" style="cursor:pointer">User Manual</a><a class="sub-dropdown dropdown__link dropdown--hoverable" style="cursor:pointer">Developer Manual</a></ul><ul class="dropdown__menu" style="left:160px;display:none"></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Community</a><ul class="dropdown__menu"><span><li><a class="dropdown__link" href="/docs/sig/overview/list">Special Interest Group(SIG)</a></li></span><span><li><a class="dropdown__link" href="/docs/honor/overview">Community Honors</a></li></span><span><li><a href="http://github.com/oceanbase/oceanbase/discussions" target="_blank" rel="noopener noreferrer" class="dropdown__link">GitHub Discussion<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></span><span><li><a href="https://join.slack.com/t/oceanbase/shared_invite/zt-1e25oz3ol-lJ6YNqPHaKwY_mhhioyEuw" target="_blank" rel="noopener noreferrer" class="dropdown__link">Slack<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></span><span><li><a href="https://ask.oceanbase.com/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Forum (in Chinese)<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></span><span><li><a href="https://stackoverflow.com/questions/tagged/oceanbase" target="_blank" rel="noopener noreferrer" class="dropdown__link">Stack Overflow<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></span></ul><ul class="dropdown__menu" style="left:160px;display:none"></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Data + AI</a><ul class="dropdown__menu"><span><li><a href="https://oceanbase-devhub.github.io" target="_blank" rel="noopener noreferrer" class="dropdown__link">Devhub<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></span><span><li><div style="padding: 0.25rem 0.5rem; font-size: 14px; color: #4e7ff1;">AI Workshops</div></li></span><span><li><a href="https://oceanbase-devhub.github.io/ai-workshop-2024" target="_blank" rel="noopener noreferrer" class="dropdown__link">RAG Bot<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></span><span><li><a href="https://oceanbase-devhub.github.io/dify/dify@oceanbase-workshop" target="_blank" rel="noopener noreferrer" class="dropdown__link">Dify (MySQL Compatible)<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></span><span><li><a href="https://oceanbase-devhub.github.io/DB-GPT/docker/compose_examples/ob_dbgpt_tutorial" target="_blank" rel="noopener noreferrer" class="dropdown__link">DB-GPT<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></span></ul><ul class="dropdown__menu" style="left:160px;display:none"></ul></div><a href="https://en.oceanbase.com/softwarecenter" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Downloads<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/oceanbase" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/blogs/arch/all-in-one">Architectural Introduction</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/blogs/feat/io-isolation">Features Introduction</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/blogs/tech/adaptive-sql-execution-engine">Technical Introduction</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/adaptive-sql-execution-engine">Adaptive Techniques in the OceanBase SQL Execution Engine</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/alter-table">Principles of ALTER TABLE in OceanBase Database</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/distributed-push-down">OceanBase Distributed Pushdown Technology</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/high-concurrency">OceanBase Technical Insights for High-Concurrency Scenarios</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/ob-schema">What Is a Schema in OceanBase Database?</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/blogs/tech/parallel-execution-I">Mastering Parallel Execution in OceanBase Database: Part 1 - Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/parallel-execution-II">Mastering Parallel Execution in OceanBase Database: Part 2 - Set the DOP</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/parallel-execution-III">Mastering Parallel Execution in OceanBase Database: Part 3 - Concurrency Control and Queuing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/parallel-execution-IV">Mastering Parallel Execution in OceanBase Database: Part 4 - Parallel Execution Types</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/query-engines">Evolution of Database Query Engines</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/refine-performance">How We Approach Improving Distributed Query Performance</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/storage-engine">Storage Engine of OceanBase Database V4.x Cuts Historical Database Costs by over 50%</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/tp-to-ap">From OLTP to OLAP: Exploration and practice of the OceanBase SQL engine</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/trans-recovery">Principles and Practices of Transaction Recovery in Distributed Databases</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/truncated-table">Why Truncated Tables Cannot Be Recycled in OceanBase Database V4.x?</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/tech/vector-search">Vector capabilities of OceanBase Database: find similar images in a blink</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/blogs/users/AXA">Corporate Cases</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/blogs/showcases/architectural-evolution">Highlights</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/blogs/others/flink-and-ob">Others</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Technical Introduction</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Mastering Parallel Execution in OceanBase Database: Part 1 - Introduction</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Mastering Parallel Execution in OceanBase Database: Part 1 - Introduction</h1></header>
<blockquote>
<p>Message from the Author:<br>
<!-- -->   This is a long-expected systematic guide on parallel execution (PX).<br>
<!-- -->   Since 2019, parallel execution has been widely implemented in various scenarios, playing an increasingly more important role.<br>
<!-- -->   This guide is here to help business teams master the parallel execution feature.</p>
</blockquote>
<p>Parallel execution enables OceanBase Database to execute an SQL statement using multiple CPU cores and I/O threads. This article introduces how parallel execution works, as well as how to control, manage, and monitor parallel execution in OceanBase Database.</p>
<p>This is the first article of a seven-part series on parallel execution.</p>
<p>Part 1</p>
<p><a href="https://oceanbase.github.io/docs/blogs/tech/parallel-execution-I" target="_blank" rel="noopener noreferrer">Introduction</a></p>
<p>Part 2</p>
<p><a href="https://oceanbase.github.io/docs/blogs/tech/parallel-execution-II" target="_blank" rel="noopener noreferrer">Set the DOP</a></p>
<p>Part 3</p>
<p><a href="https://oceanbase.github.io/docs/blogs/tech/parallel-execution-III" target="_blank" rel="noopener noreferrer">Concurrency Control and Queuing</a></p>
<p>Part 4</p>
<p><a href="https://oceanbase.github.io/docs/blogs/tech/parallel-execution-IV" target="_blank" rel="noopener noreferrer">Parallel Execution Types</a></p>
<p>Part 5</p>
<p><a href="https://oceanbase.github.io/docs/blogs/tech/parallel-execution-V" target="_blank" rel="noopener noreferrer">Parallel Execution Parameters</a></p>
<p>Part 6</p>
<p><a href="https://oceanbase.github.io/docs/blogs/tech/parallel-execution-VI" target="_blank" rel="noopener noreferrer">Troubleshooting and Tuning Tips</a></p>
<p>Part 7</p>
<p><a href="https://oceanbase.github.io/docs/blogs/tech/parallel-execution-VII" target="_blank" rel="noopener noreferrer">Get Started with a PoC Test</a></p>
<h1>1 Introduction</h1>
<p>Parallel execution splits a query task into multiple subtasks and allows them to run on multiple processors in parallel to improve the execution efficiency of the query task. In modern computer systems, multi-core processors, multithreading, and high-speed network connections are widely used, which makes parallel execution an efficient query technology.</p>
<p>This technology significantly reduces the response time of compute-intensive large queries, and comes in handy in fields such as batch data import/export and quick index table creation. It is widely applied in business scenarios such as offline data warehouses, real-time reports, and online big data analytics.</p>
<p>Parallel execution is well suited for the following scenarios:</p>
<ul>
<li>Scanning and joining of large tables, and sorting or aggregation of a large amount of data</li>
<li>DDL operations on large tables, such as changing the primary key or column type and creating indexes</li>
<li>Table creation based on existing big data, such as creating a table by using the <code>CREATE TABLE AS SELECT</code> statement</li>
<li>Batch data insertion, deletion, and updates</li>
</ul>
<p>In this article, you will learn about:</p>
<ul>
<li>
<p>Scenarios where parallel execution is applicable</p>
</li>
<li>
<p>Scenarios where parallel execution is inapplicable</p>
</li>
<li>
<p>Hardware requirements</p>
</li>
<li>
<p>Technical mechanism of parallel execution</p>
</li>
<li>
<p>Worker threads of parallel execution</p>
</li>
<li>
<p>Performance optimization through load balancing</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="11-scenarios-where-parallel-execution-is-applicable">1.1 Scenarios Where Parallel Execution Is Applicable<a href="#11-scenarios-where-parallel-execution-is-applicable" class="hash-link" aria-label="Direct link to 1.1 Scenarios Where Parallel Execution Is Applicable" title="Direct link to 1.1 Scenarios Where Parallel Execution Is Applicable">​</a></h2>
<p>Parallel execution makes full use of multiple CPU cores and I/O resources to reduce the SQL execution time.</p>
<p>Parallel execution outperforms serial execution in the following circumstances:</p>
<ul>
<li>A large amount of data to access</li>
<li>Low SQL concurrency</li>
<li>A need for low latency</li>
<li>Sufficient hardware resources</li>
</ul>
<p>Parallel execution uses multiple processors to concurrently handle the same task. This can improve the system performance if your system has the following characteristics:</p>
<ul>
<li>Symmetric multiprocessing (SMP) system and cluster</li>
<li>Sufficient I/O bandwidth</li>
<li>Enough memory resources for memory-intensive operations such as sorting and hash table creation</li>
<li>Appropriate system load or system load with peak-valley characteristics, such as a system load that remains below 30%</li>
</ul>
<p>Otherwise, parallel execution delivers little improvement in performance. It results in poor performance in a system with a high load, small memory size, or insufficient I/O bandwidth.</p>
<p>In addition to analytical systems such as offline data warehousing, real-time report, and online big data analytics systems, parallel execution can also be used to accelerate DDL operations and batch data processing in the online transaction processing (OLTP) field. However, parallel execution is inapplicable to general SELECT and DML statements in an OLTP system.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="12-scenarios-where-parallel-execution-is-inapplicable">1.2 Scenarios Where Parallel Execution Is Inapplicable<a href="#12-scenarios-where-parallel-execution-is-inapplicable" class="hash-link" aria-label="Direct link to 1.2 Scenarios Where Parallel Execution Is Inapplicable" title="Direct link to 1.2 Scenarios Where Parallel Execution Is Inapplicable">​</a></h2>
<p>In serial execution, a single thread is used to execute database operations. Serial execution outperforms parallel execution in the following circumstances:</p>
<ul>
<li>
<p>A small amount of data to access</p>
</li>
<li>
<p>High concurrency</p>
</li>
<li>
<p>A query execution time less than 100 ms</p>
</li>
</ul>
<p>Parallel execution is inapplicable in the following scenarios:</p>
<ul>
<li>
<p>Typical SQL queries in the system are executed within milliseconds. A parallel query has a millisecond-level scheduling overhead. For a short query, the benefit of parallel execution is completely offset by the scheduling overhead.</p>
</li>
<li>
<p>The system load is high. Parallel execution is designed to make full use of idle system resources. For a system with a high load, parallel execution may fail to bring extra benefits but compromise the overall system performance.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="13-hardware-requirements">1.3 Hardware Requirements<a href="#13-hardware-requirements" class="hash-link" aria-label="Direct link to 1.3 Hardware Requirements" title="Direct link to 1.3 Hardware Requirements">​</a></h2>
<p>Parallel execution does not have special requirements on the hardware. However, the number of CPU cores, memory size, storage I/O performance, or network bandwidth can become a bottleneck that affects the parallel execution performance.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="14-technical-mechanism-of-parallel-execution">1.4 Technical Mechanism of Parallel Execution<a href="#14-technical-mechanism-of-parallel-execution" class="hash-link" aria-label="Direct link to 1.4 Technical Mechanism of Parallel Execution" title="Direct link to 1.4 Technical Mechanism of Parallel Execution">​</a></h2>
<p>Parallel execution splits an SQL query task into multiple subtasks and schedules these subtasks to multiple processors.</p>
<p>This section covers the following content:</p>
<ul>
<li>
<p>Parallel execution of SQL statements</p>
</li>
<li>
<p>Producer-consumer pipeline model</p>
</li>
<li>
<p>Granules of parallel execution</p>
</li>
<li>
<p>Data distribution methods between the producer and the consumer</p>
</li>
<li>
<p>Data transmission mechanism between the producer and the consumer</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="141-parallel-execution-of-sql-statements">1.4.1 Parallel Execution of SQL Statements<a href="#141-parallel-execution-of-sql-statements" class="hash-link" aria-label="Direct link to 1.4.1 Parallel Execution of SQL Statements" title="Direct link to 1.4.1 Parallel Execution of SQL Statements">​</a></h3>
<p>When a parallel execution plan is generated for an SQL query, the query is executed in the following steps:</p>
<ol>
<li>
<p>The main thread, which is responsible for receiving and parsing SQL queries, allocates the worker threads required for parallel execution in advance. These worker threads may come from multiple servers in the cluster.</p>
</li>
<li>
<p>The main thread enables the <strong>PX coordinator</strong>.</p>
</li>
<li>
<p>The PX coordinator parses the execution plan into multiple steps and schedules the steps from bottom up. Each operation is designed to be eligible for parallel execution.</p>
</li>
<li>
<p>After all operations are executed in parallel, the PX coordinator receives the calculation results and transfers the results to the upper-layer operator (such as the Aggregate operator) for serial execution of operations ineligible for parallel execution, such as the final SUM operation.</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="142-producer-consumer-pipeline-model">1.4.2 Producer-consumer Pipeline Model<a href="#142-producer-consumer-pipeline-model" class="hash-link" aria-label="Direct link to 1.4.2 Producer-consumer Pipeline Model" title="Direct link to 1.4.2 Producer-consumer Pipeline Model">​</a></h3>
<p>The producer-consumer model is used for pipelined execution. The PX coordinator parses the execution plan into multiple steps. Each step is called a <strong>data flow operation (DFO)</strong>.</p>
<p>Generally, the PX coordinator starts two DFOs at the same time. The two DFOs are connected in producer-consumer mode for inter-DFO parallel execution. Each DFO is executed by a group of threads. This is called intra-DFO parallel execution. The number of threads used for a DFO is called the <strong>degree of parallelism (DOP)</strong>.</p>
<p>A consumer DFO in a phase will become a producer DFO in the next phase. Under the coordination by the PX coordinator, the consumer DFO and producer DFO are started at the same time.</p>
<p>As shown in the following figure:</p>
<ol>
<li>
<p>The data generated by DFO A is transmitted in real time to DFO B for calculation.</p>
</li>
<li>
<p>After calculation, DFO B stores the data in the current thread and waits for the upper-layer DFO C to start.</p>
</li>
<li>
<p>When DFO B is notified that DFO C has been started, it switches to the producer role and starts to transmit data to DFO C. After DFO C receives the data, it starts calculation.</p>
</li>
</ol>
<p><img decoding="async" loading="lazy" alt="1705634262" src="/assets/images/1705634262343-3281cd5b19f386258455f28b655d6357.png" width="1330" height="824" class="img_ev3q"></p>
<p>Here is a sample query:
<img decoding="async" loading="lazy" alt="1" src="/assets/images/1-44eb05a98f7b6fe54adf4905c59e160a.png" width="1414" height="334" class="img_ev3q"></p>
<p>The execution plan for the query statement is as follows:
<img decoding="async" loading="lazy" alt="2" src="/assets/images/2-522eac2f1ad428a152f9670eecb7a5d6.png" width="1912" height="1402" class="img_ev3q"></p>
<p>The execution plan of the <code>SELECT</code> statement first performs a full-table scan on the <code>game</code> table to group the data by team, and then calculates the total score of each team. The following figure demonstrates the query execution process.</p>
<p><img decoding="async" loading="lazy" src="https://obcommunityprod.oss-cn-shanghai.aliyuncs.com/prod/blog/2024-01/1705634280908.png" alt="1705634280" class="img_ev3q"></p>
<p>As shown in the preceding figure, six threads are used for the query.</p>
<ul>
<li>Step 1: The first three threads are responsible for scanning the <code>game</code> table. They separately pre-aggregate the <code>game.team</code> data.</li>
<li>Step 2: The rest three threads are responsible for the final aggregation of the pre-aggregated data.</li>
<li>Step 3: The PX coordinator returns the final aggregation results to the client.</li>
</ul>
<p>The data sent from Step 1 to Step 2 is hashed by using the <code>game.team</code> field to determine the thread to which the pre-aggregated data is to be sent.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="143-granules-of-parallel-execution">1.4.3 Granules of Parallel Execution<a href="#143-granules-of-parallel-execution" class="hash-link" aria-label="Direct link to 1.4.3 Granules of Parallel Execution" title="Direct link to 1.4.3 Granules of Parallel Execution">​</a></h3>
<p><strong>Granule</strong> is the basic working unit for parallel data scan. OceanBase Database divides a table scan task into multiple granules. Each granule describes a part of the table scan task. As a granule cannot span across table partitions, it is confined to one partition.</p>
<p>Two types of granules are supported:</p>
<ul>
<li><strong>Partition granule</strong></li>
</ul>
<p>A partition granule describes a whole partition. Therefore, the number of partition granules of a scan task is equal to the number of partitions involved in the scan task. Here, a partition can be one in a primary table or an index table.</p>
<p>Partition granules are often used in partition-wise joins, where the partition granules ensure that the corresponding partitions of two tables are processed by the same worker thread.</p>
<ul>
<li><strong>Block granule</strong></li>
</ul>
<p>A block granule describes a segment of continuous data in a partition. Generally, block granules are used to divide data in a data scan scenario. Each partition is divided into multiple blocks. The blocks are concatenated based on specific rules to form a task queue, which will be consumed by PX worker threads.</p>
<p><img decoding="async" loading="lazy" alt="1705634306" src="/assets/images/1705634306537-00732c934b974efba46657a4e6b3c418.png" width="1408" height="844" class="img_ev3q"></p>
<p>Given a DOP, the optimizer will automatically choose to divide data into partition granules or block granules for balancing of scan tasks. If the optimizer chooses block granules, the parallel execution framework divides data into blocks during running and ensures that each block is of an appropriate size, which is not too large or small. An excessively large block size can lead to data skew, where some threads cannot be fully used. An excessively small size can lead to frequent scans, which increase the switching overhead.</p>
<p>After partition granules are divided, each granule corresponds to a scan task. The TABLE SCAN operator handles the scan tasks one by one.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="144-data-distribution-methods-between-the-producer-and-the-consumer">1.4.4 Data Distribution Methods between the Producer and the Consumer<a href="#144-data-distribution-methods-between-the-producer-and-the-consumer" class="hash-link" aria-label="Direct link to 1.4.4 Data Distribution Methods between the Producer and the Consumer" title="Direct link to 1.4.4 Data Distribution Methods between the Producer and the Consumer">​</a></h3>
<p>A data distribution method is the method used by a group of PX worker threads (producers) to send data to another group of PX worker threads (consumers). The optimizer selects a data redistribution method based on a series of optimization strategies to achieve the optimal performance.</p>
<p>General data distribution methods in parallel execution include:</p>
<ul>
<li><strong>Hash distribution</strong></li>
</ul>
<p>In hash distribution, the producer hashes the data based on the distribution key and obtains the modulus to determine the consumer worker thread to which the data is to be sent. In most cases, this method can evenly distribute data across multiple consumer worker threads.</p>
<ul>
<li><strong>Pkey distribution</strong></li>
</ul>
<p>In pkey distribution, the producer determines through calculation the partition in the target table to which a data row belongs and sends the row data to a consumer thread responsible for this partition.</p>
<p>Pkey distribution is commonly used in partial partition-wise joins, where you can perform partition-wise joins between the consumer data and the producer data without the need to redistribute the consumer data. This method reduces network communication and improves performance.</p>
<ul>
<li><strong>Pkey hash distribution</strong></li>
</ul>
<p>In pkey hash distribution, the producer first calculates the partition in the target table to which a data row belongs and hashes the data based on the distribution key to determine the consumer thread to which the data is to be sent.</p>
<p>Pkey hash distribution is commonly used in parallel DML scenarios where a partition can be concurrently updated by multiple threads. Pkey hash distribution can ensure that rows with identical values are processed by the same thread and that rows with different values are evenly distributed to multiple threads.</p>
<ul>
<li><strong>Broadcast distribution</strong></li>
</ul>
<p>In broadcast distribution, the producer sends all data rows to each consumer thread so that each consumer thread has the full data of the producer.</p>
<p>Broadcast distribution is commonly used to copy data from small tables to all nodes involved in a join. Then, joins are executed locally to reduce network communication.</p>
<ul>
<li><strong>Broadcast to host distribution</strong></li>
</ul>
<p>In broadcast to host distribution, the producer sends all rows to each consumer node so that each consumer node has the full data of the producer. Then, the consumer threads on each node process the data in a collaborative manner.</p>
<p>Broadcast to host distribution is commonly used in <code>NESTED LOOP JOIN</code> and <code>SHARED HASH JOIN</code> scenarios. In a <code>NESTED LOOP JOIN</code> scenario, each consumer thread obtains a part of the shared data as the driver data for the join operation on the target table. In a <code>SHARED HASH JOIN</code> scenario, the consumer threads jointly build a hash table based on the shared data. This avoids the situation where each consumer thread independently builds a hash table identical to that of others, thereby reducing the overhead.</p>
<ul>
<li><strong>Range distribution</strong></li>
</ul>
<p>In range distribution, the producer divides data into ranges for different consumer threads to process.</p>
<p>Range distribution is commonly used in sorting scenarios. Each consumer thread only needs to sort the data allocated to it. This ensures that the data is globally ordered.</p>
<ul>
<li><strong>Random distribution</strong></li>
</ul>
<p>In random distribution, the producer randomly scatters the data and sends the data to the consumer threads so that each consumer thread processes an almost equal amount of data, thereby achieving load balancing.</p>
<p>Random distribution is commonly used in multithreaded parallel <code>UNION ALL</code> scenarios, where data is scattered only for load balancing and the scattered data is not associated.</p>
<ul>
<li><strong>Hybrid hash distribution</strong></li>
</ul>
<p>Hybrid hash distribution is an adaptive distribution method used in join operations. Based on collected statistics, OceanBase Database provides a group of parameters to define regular values and frequent values. In hybrid hash distribution, hash distribution is used for regular values on both sides of a join, broadcast distribution is used for frequent values on the left side, and random distribution is used for frequent values on the right side.<br>
<img decoding="async" loading="lazy" alt="1705634332" src="/assets/images/1705634332874-bc08619e618ff24fc6851607eb08afb9.png" width="1190" height="668" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="145-data-transmission-mechanism-between-the-producer-and-the-consumer">1.4.5 Data Transmission Mechanism between the Producer and the Consumer<a href="#145-data-transmission-mechanism-between-the-producer-and-the-consumer" class="hash-link" aria-label="Direct link to 1.4.5 Data Transmission Mechanism between the Producer and the Consumer" title="Direct link to 1.4.5 Data Transmission Mechanism between the Producer and the Consumer">​</a></h3>
<p>The PX coordinator starts two DFOs at the same time. The two DFOs are connected in producer-consumer mode for inter-DFO parallel execution. A transmission network is required for transmitting data between the producer and the consumer.</p>
<p>For example, if the producer DFO uses two threads (DOP = 2) for data scan and the consumer DFO uses three threads (DOP = 3) for data aggregation, each producer thread creates three virtual links to the consumer threads. Totally six virtual links are created, as shown in the following figure.</p>
<p><img decoding="async" loading="lazy" alt="1705634356" src="/assets/images/1705634356164-450cb1b2465c361019526d5c8fd46faf.png" width="1202" height="918" class="img_ev3q"></p>
<p>The virtual transmission network created between the producer and the consumer is called the data transfer layer (DTL). In the parallel execution framework of OceanBase Database, all control messages and data rows are sent and received over the DTL. Each worker thread can establish thousands of external virtual links, providing high scalability. The DTL also provides features such as data buffering, batch data sending, and automatic throttling.</p>
<p>If the two ends of a DTL link are on the same node, the DTL transfers messages through memory copy. If the two ends of a DTL link are on different nodes, the DTL transfers messages through network communication.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="15-worker-threads-of-parallel-execution">1.5 Worker Threads of Parallel Execution<a href="#15-worker-threads-of-parallel-execution" class="hash-link" aria-label="Direct link to 1.5 Worker Threads of Parallel Execution" title="Direct link to 1.5 Worker Threads of Parallel Execution">​</a></h2>
<p>A parallel query uses two types of threads: one main thread and multiple PX worker threads. The main thread uses the same thread pool as threads for normal transaction processing (TP) queries. PX worker threads come from a dedicated thread pool.</p>
<p>OceanBase Database uses a dedicated thread pool model to allocate PX worker threads. Each tenant has a dedicated PX thread pool on each of its nodes. All PX worker threads are allocated from this thread pool.</p>
<p>Before the PX coordinator schedules each DFO, it requests threads from the thread pool. After a DFO is executed, the threads for the DFO are immediately released.</p>
<p>The initial size of the thread pool is 0. It can be dynamically scaled out without an upper limit. To avoid excessive idle threads, the thread pool introduces the automatic reclamation mechanism. For any thread:</p>
<ul>
<li>If the thread is left idle for more than 10 minutes and the number of remaining threads in the thread pool exceeds 8, the thread will be reclaimed and destroyed.</li>
<li>If the thread is left idle for more than 60 minutes, it will be destroyed unconditionally.</li>
</ul>
<p>Theoretically, the thread pool has no upper limit in size. However, the following mechanisms actually contribute to an upper limit:</p>
<ol>
<li>
<p>Threads must be requested from the Admission module before parallel execution. Parallel execution can start only after threads are successfully requested. This mechanism can limit the number of parallel queries. For more information about the Admission module, see <a href="https://open.oceanbase.com/blog/7085150528" target="_blank" rel="noopener noreferrer">Mastering Parallel Execution in OceanBase Database: Part 3 - Concurrency Control and Queuing</a>.</p>
</li>
<li>
<p>To process a query, N threads can be requested from the thread pool at a time, where N = Value of <code>MIN_CPU</code> of the unit config for the resource units of the tenant × Value of <code>px_workers_per_cpu_quota</code>. At most N threads are allocated even if more than N threads are requested. <code>px_workers_per_cpu_quota</code> is a tenant-level parameter whose default value is <code>10</code>. Assume that the value of <code>MIN_CPU</code> is <code>4</code> and the value of <code>px_workers_per_cpu_quota</code> is <code>10</code>, N = 4 × 10 = 40. In this case, if a DFO with a DOP of 100 requests 30 threads from Node A and 70 threads from Node B, the DFO can actually request 30 threads from Node A and 40 threads from Node B. Its actual DOP is 70.</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="16-performance-optimization-through-load-balancing">1.6 Performance Optimization through Load Balancing<a href="#16-performance-optimization-through-load-balancing" class="hash-link" aria-label="Direct link to 1.6 Performance Optimization through Load Balancing" title="Direct link to 1.6 Performance Optimization through Load Balancing">​</a></h2>
<p>To achieve the optimal performance, allocate the same number of tasks to each worker thread as far as possible.</p>
<p>If data is divided based on block granules, the tasks are dynamically allocated to worker threads. This can minimize the imbalance in workloads. In other words, the workload of each worker thread does not significantly exceed those of others. If data is divided based on partition granules, you can optimize the performance by ensuring that the number of tasks is an integral multiple of the number of worker threads. This is very useful for partition-wise joins and parallel DML.</p>
<p>Assume that a table has 16 partitions and that the amount of data in each partition is almost the same. You can use 16 worker threads (DOP = 16) to finish the job with 1/16 of the time otherwise required, 5 worker threads to finish the job with 1/5 of the time otherwise required, or 2 threads to finish the job with 1/2 the time otherwise required.</p>
<p>However, if you use 15 worker threads to process the data of 16 partitions, the first thread will start to process the data of the 16th partition after it finishes processing the data of the first partition. Other threads will become idle after they finish processing the data of their respective allocated partition. If the amount of data in each partition is close, this configuration will result in poor performance. If the amount of data in each partition varies, the actual performance depends on the actual situation.</p>
<p>Similarly, assume that you use 6 threads to process the data of 16 partitions and that each partition has a close amount of data. Each thread will start to process the data of a second partition after it finishes processing the data of the first partition. However, only four threads will process the data of a third partition while the other two threads will become idle.</p>
<p>Given N partitions and P worker threads, you cannot simply calculate the time required for parallel execution by dividing N by P. You need to consider the situation where some threads may need to wait for other threads to complete data processing for the last partition. You can specify an appropriate DOP to minimize the imbalance in workloads and optimize the performance.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/oceanbase/oceanbase.github.io/tree/main/docs/blogs/tech/parallel-execution-I.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/blogs/tech/ob-schema"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">What Is a Schema in OceanBase Database?</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/blogs/tech/parallel-execution-II"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Mastering Parallel Execution in OceanBase Database: Part 2 - Set the DOP</div></a></nav><div>Loading...</div></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#11-scenarios-where-parallel-execution-is-applicable" class="table-of-contents__link toc-highlight">1.1 Scenarios Where Parallel Execution Is Applicable</a></li><li><a href="#12-scenarios-where-parallel-execution-is-inapplicable" class="table-of-contents__link toc-highlight">1.2 Scenarios Where Parallel Execution Is Inapplicable</a></li><li><a href="#13-hardware-requirements" class="table-of-contents__link toc-highlight">1.3 Hardware Requirements</a></li><li><a href="#14-technical-mechanism-of-parallel-execution" class="table-of-contents__link toc-highlight">1.4 Technical Mechanism of Parallel Execution</a><ul><li><a href="#141-parallel-execution-of-sql-statements" class="table-of-contents__link toc-highlight">1.4.1 Parallel Execution of SQL Statements</a></li><li><a href="#142-producer-consumer-pipeline-model" class="table-of-contents__link toc-highlight">1.4.2 Producer-consumer Pipeline Model</a></li><li><a href="#143-granules-of-parallel-execution" class="table-of-contents__link toc-highlight">1.4.3 Granules of Parallel Execution</a></li><li><a href="#144-data-distribution-methods-between-the-producer-and-the-consumer" class="table-of-contents__link toc-highlight">1.4.4 Data Distribution Methods between the Producer and the Consumer</a></li><li><a href="#145-data-transmission-mechanism-between-the-producer-and-the-consumer" class="table-of-contents__link toc-highlight">1.4.5 Data Transmission Mechanism between the Producer and the Consumer</a></li></ul></li><li><a href="#15-worker-threads-of-parallel-execution" class="table-of-contents__link toc-highlight">1.5 Worker Threads of Parallel Execution</a></li><li><a href="#16-performance-optimization-through-load-balancing" class="table-of-contents__link toc-highlight">1.6 Performance Optimization through Load Balancing</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="http://github.com/oceanbase/oceanbase/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Discussion<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://join.slack.com/t/oceanbase/shared_invite/zt-1e25oz3ol-lJ6YNqPHaKwY_mhhioyEuw" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/oceanbase" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://ask.oceanbase.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Forum (in Chinese)<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">SIG</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/sig/AI/sig_intro">AI</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/sig/cloud-native/sig_intro">cloud-native</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/sig/compilation/sig_intro">compilation</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/sig/develop-tools/sig_intro">develop-tools</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/sig/miniob/sig_intro">MiniOB</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/sig/obdiag/sig_intro">obdiag</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/sig/operation/sig_intro">operation</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://en.oceanbase.com/about" target="_blank" rel="noopener noreferrer" class="footer__link-item">About OceanBase<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs/arch/all-in-one">Blogs</a></li><li class="footer__item"><a href="https://github.com/oceanbase/oceanbase" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 OceanBase, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>